{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd    \n",
    "import json\n",
    "import itertools\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA  \n",
    "from datetime import datetime\n",
    "from nutrlink import NutrLink\n",
    "nl = NutrLink(url=\"https://dev-api.ddt-dst.cc/nutrients/station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def INDUSTRY():\n",
    "\n",
    "    res = nl.get(\"tw_industry\")\n",
    "    filtered = res[res['ticker'].str.len() == 4]\n",
    "    selected_columns = ['ticker', 'twse_ind']\n",
    "    use_df = filtered[selected_columns]\n",
    "    use_df = use_df.reset_index(drop=True)\n",
    "    \n",
    "    # total_data_1 = pd.read_parquet(\n",
    "    #     f\"{PLUMBER_HOST}tej/stock/twn/aind\",\n",
    "    #     storage_options={\n",
    "    #         \"gcp-token\": json.dumps(token)\n",
    "    #     },\n",
    "    # )\n",
    "\n",
    "    # filtered = total_data_1[total_data_1['coid'].str.len() == 4]\n",
    "    # selected_columns = ['coid', 'tejind4_c']\n",
    "    # use_df = filtered[selected_columns]\n",
    "    # use_df = use_df.reset_index(drop=True)\n",
    "\n",
    "    return use_df\n",
    "\n",
    "class use_time:\n",
    "    def __init__(self, start_year, end_year):\n",
    "        self.start_year = start_year+1\n",
    "        self.end_year = end_year\n",
    "\n",
    "    def generate_df(self):\n",
    "        dates = [datetime(year, 12, 1).strftime('%Y-%m-%d') for year in range(self.start_year, self.end_year + 1)]\n",
    "        df = pd.DataFrame(dates, columns=['date'])\n",
    "        \n",
    "        # months = [3, 6, 9, 12]  # æ¯å­£çš„ç¬¬ä¸€å¤©\n",
    "        # dates = [\n",
    "        #     datetime(year, month, 1).strftime('%Y-%m-%d')\n",
    "        #     for year in range(self.start_year, self.end_year + 1)\n",
    "        #     for month in months\n",
    "        # ]\n",
    "        # df = pd.DataFrame(dates, columns=['date'])\n",
    "        return df\n",
    "\n",
    "class REVENUE:\n",
    "    def __init__(self, time_df):\n",
    "        self.time = pd.to_datetime(time_df['date'])\n",
    "        self.time = self.time.dt.tz_localize(\"UTC\")\n",
    "        self.time_ori = time_df['date'].astype(str)\n",
    "\n",
    "    def generate_df(self, code):\n",
    "        \n",
    "        start_date = self.time.min()\n",
    "        end_date = self.time.max()\n",
    "\n",
    "        filters = [\n",
    "            (\"mdate\", \">=\", start_date),\n",
    "            (\"mdate\", \"<=\", end_date),\n",
    "            ]\n",
    "\n",
    "        read_data = nl.get(\"tej_stock_twn_asale\", filters=filters)\n",
    "        revenue_table = read_data.loc[:, ['coid', 'mdate', code]]\n",
    "        revenue_filtered = revenue_table.loc[\n",
    "            (revenue_table['coid'].str.len() == 4)\n",
    "            ]\n",
    "\n",
    "\n",
    "        # all_data = []\n",
    "        # for date in self.time_ori:\n",
    "        #     read_data = pd.read_parquet(\n",
    "        #         f\"{PLUMBER_HOST}tej/stock/twn/asale\",\n",
    "        #         storage_options={\n",
    "        #             \"gcp-token\": json.dumps(token),\n",
    "        #             \"start-date\": date,\n",
    "        #             \"end-date\": date\n",
    "        #             },\n",
    "        #         )\n",
    "\n",
    "        #     revenue_table_ori = read_data.loc[:, ['coid', 'mdate', 'd0007']]\n",
    "        #     revenue_filtered_ori = revenue_table_ori[revenue_table_ori['coid'].str.len() == 4]\n",
    "        #     all_data.append(revenue_filtered_ori)\n",
    "\n",
    "        # final_df = pd.concat(all_data, ignore_index=True)\n",
    "        return revenue_filtered\n",
    "    \n",
    "class RESERVE():\n",
    "    def __init__(self, time_df):\n",
    "        self.time = pd.to_datetime(time_df['date'])\n",
    "        self.time = self.time.dt.tz_localize(\"UTC\")\n",
    "        self.time_ori = time_df['date'].astype(str)\n",
    "        \n",
    "    def generate_df(self, code):\n",
    "        \n",
    "        start_date = self.time.min()\n",
    "        end_date = self.time.max()\n",
    "        \n",
    "        filters = [\n",
    "            (\"mdate\", \">=\", start_date),\n",
    "            (\"mdate\", \"<=\", end_date),\n",
    "            ]\n",
    "        \n",
    "        res = nl.get(\"tej_financial_statements_twn_aim1aq\", filters=filters)\n",
    "        reserve_table = res[res['acc_code'] == code]\n",
    "        reserve_filtered = reserve_table.loc[\n",
    "            (reserve_table['coid'].str.len() == 4)\n",
    "            ]\n",
    "        \n",
    "        return reserve_filtered\n",
    "    \n",
    "class GM():\n",
    "    def __init__(self, time_df):\n",
    "        self.time = pd.to_datetime(time_df['date'])\n",
    "        self.time = self.time.dt.tz_localize(\"UTC\")\n",
    "        self.time_ori = time_df['date'].astype(str)\n",
    "        \n",
    "    def generate_df(self, code):\n",
    "        \n",
    "        start_date = self.time.min()\n",
    "        end_date = self.time.max()\n",
    "        \n",
    "        filters = [\n",
    "            (\"mdate\", \">=\", start_date),\n",
    "            (\"mdate\", \"<=\", end_date),\n",
    "            ]\n",
    "        \n",
    "        res = nl.get(\"tej_financial_statements_twn_aim1aq\", filters=filters)\n",
    "        reserve_table = res[res['acc_code'] == code]\n",
    "        reserve_filtered = reserve_table.loc[\n",
    "            (reserve_table['coid'].str.len() == 4)\n",
    "            ]\n",
    "        \n",
    "        return reserve_filtered\n",
    "    \n",
    "class OPM():\n",
    "    def __init__(self, time_df):\n",
    "        self.time = pd.to_datetime(time_df['date'])\n",
    "        self.time = self.time.dt.tz_localize(\"UTC\")\n",
    "        self.time_ori = time_df['date'].astype(str)\n",
    "        \n",
    "    def generate_df(self, code):\n",
    "        \n",
    "        start_date = self.time.min()\n",
    "        end_date = self.time.max()\n",
    "        \n",
    "        filters = [\n",
    "            (\"mdate\", \">=\", start_date),\n",
    "            (\"mdate\", \"<=\", end_date),\n",
    "            ]\n",
    "        \n",
    "        res = nl.get(\"tej_financial_statements_twn_aim1aq\", filters=filters)\n",
    "        reserve_table = res[res['acc_code'] == code]\n",
    "        reserve_filtered = reserve_table.loc[\n",
    "            (reserve_table['coid'].str.len() == 4)\n",
    "            ]\n",
    "        \n",
    "        return reserve_filtered\n",
    "    \n",
    "class MONEY():\n",
    "    def __init__(self, time_df):\n",
    "        self.time = pd.to_datetime(time_df['date'])\n",
    "        self.time = self.time.dt.tz_localize(\"UTC\")\n",
    "        self.time_ori = time_df['date'].astype(str)\n",
    "        \n",
    "    def generate_df(self, code):\n",
    "        \n",
    "        start_date = self.time.min()\n",
    "        end_date = self.time.max()\n",
    "        \n",
    "        filters = [\n",
    "            (\"mdate\", \">=\", start_date),\n",
    "            (\"mdate\", \"<=\", end_date),\n",
    "            ]\n",
    "        \n",
    "        res = nl.get(\"tej_financial_statements_twn_aim1aq\", filters=filters)\n",
    "        reserve_table = res[res['acc_code'] == code]\n",
    "        reserve_filtered = reserve_table.loc[\n",
    "            (reserve_table['coid'].str.len() == 4)\n",
    "            ]\n",
    "        \n",
    "        return reserve_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¨­å®šç”¢æ¥­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_industry = 'semiconductor'\n",
    "#save_industry_2ç‚ºå„²å­˜combind 2011å¹´å‰è³‡æ–™çš„å®Œæ•´2006~æœ€æ–°å¹´åº¦è³‡æ–™\n",
    "save_industry_2 = 'semiconductor_2'\n",
    "industry_composition = 'my_use'\n",
    "save_signal_lights = 'Textile_signal_lights'\n",
    "stock_path = Path.cwd() / \"goodinfo\" / f\"{industry_composition}\"\n",
    "industry_code = \"M2324\"\n",
    "industry = INDUSTRY()\n",
    "industry['twse_ind'] = industry['twse_ind'].str.strip()\n",
    "use_industry = 'åŠå°é«”'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2011å¹´å¾Œè²¡å ±è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_stock = industry.loc[(industry['twse_ind'] == use_industry)]\n",
    "use_stock = use_stock.reset_index(drop=True)\n",
    "\n",
    "#å…ˆä½¿ç”¨ä»¥2011 Q1çš„å‰20å¤§å¸‚å€¼\n",
    "start_date = datetime.fromisoformat(\"2011-03-01 00:00:00+00:00\")\n",
    "\n",
    "filters = [\n",
    "    (\"mdate\", \"==\", start_date)\n",
    "    ]\n",
    "\n",
    "read_data = nl.get(\"tej_financial_statements_twn_aim1a\", filters=filters)\n",
    "market_value_table = read_data.iloc[np.where(read_data['acc_code'] == 'MV')[0],:]\n",
    "market_value_filtered = market_value_table[market_value_table['coid'].str.len() == 4]\n",
    "\n",
    "# è½‰æˆå­—ä¸²ä»¥é˜² coid/ticker è³‡æ–™å‹åˆ¥ä¸ä¸€è‡´\n",
    "use_ticker_list = use_stock['ticker'].astype(str).tolist()\n",
    "\n",
    "# ç¯©å‡ºåœ¨ use_stock ä¸­çš„å…¬å¸\n",
    "market_value_selected = market_value_filtered[\n",
    "    market_value_filtered['coid'].astype(str).isin(use_ticker_list)\n",
    "].copy()\n",
    "\n",
    "market_value_selected['coid'] = market_value_selected['coid'].astype(int)\n",
    "\n",
    "# ç´¡ç¹”çº–ç¶­\n",
    "# remove_tickers = [1402, 1434, 1303, 1455, 1710, 1409, 4414]\n",
    "remove_tickers = []\n",
    "\n",
    "# æ’é™¤ä¸éœ€è¦çš„ coid\n",
    "final_mv = market_value_selected[~market_value_selected['coid'].isin(remove_tickers)].copy()\n",
    "\n",
    "# top_20_mv = final_mv.sort_values(by='acc_value', ascending=False)\n",
    "top_20_mv = final_mv.sort_values(by='acc_value', ascending=False).head(5)\n",
    "\n",
    "# save_path = Path.cwd() / \"top_k\" / f\"{industry_composition}\" / f\"{save_industry}.csv\"\n",
    "# top_20_mv[['coid']].to_csv(save_path, index=False)\n",
    "file_path = Path.cwd() / \"top_k\" / f\"{industry_composition}\" / f\"{save_industry}.csv\"\n",
    "top_20_mv = pd.read_csv(file_path)\n",
    "\n",
    "# å‡è¨­ top_20_mv æ˜¯æœ‰ coid çš„ DataFrame\n",
    "coid_list = top_20_mv['coid'].astype(str).tolist()\n",
    "\n",
    "# å‡è¨­ä½ åˆ†æçš„æ˜¯ 2018~2024 å¹´\n",
    "years = list(range(2011, 2025))\n",
    "quarters = [1, 2, 3, 4]\n",
    "\n",
    "# å»ºç«‹æ‰€æœ‰ coid Ã— å¹´ Ã— å­£ çš„çµ„åˆ\n",
    "all_combinations = list(itertools.product(coid_list, years, quarters))\n",
    "\n",
    "# å»ºç«‹ DataFrame\n",
    "panel_df = pd.DataFrame(all_combinations, columns=['coid', 'year', 'quarter'])\n",
    "\n",
    "# æŒ‡æ¨™æ¬„ä½\n",
    "indicators = [\n",
    "    \"ç‡Ÿæ”¶ YoY\",\n",
    "    \"æ‡‰æ”¶å¸³æ¬¾é€±è½‰å¤©æ•¸\",\n",
    "    \"å­˜è²¨ YoY\",\n",
    "    \"å­˜è²¨é€±è½‰å¤©æ•¸\",\n",
    "    \"æ¯›åˆ©ç‡\",\n",
    "    \"ç‡Ÿæ¥­åˆ©ç›Šç‡\",\n",
    "    \"ROE\",\n",
    "    \"ç‡Ÿæ¥­ç¾é‡‘æµ\",\n",
    "    \"ç¾é‡‘æ¯”\",\n",
    "    \"çŸ­æœŸå€Ÿæ¬¾å æ¯”\"\n",
    "]\n",
    "\n",
    "# åŠ ä¸Šç©ºæ¬„ä½ï¼ˆå…ˆå¡« NaNï¼‰\n",
    "for col in indicators:\n",
    "    panel_df[col] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ™‚é–“\n",
    "start_time = 2010\n",
    "end_time = 2024\n",
    "time = use_time(start_time, end_time)\n",
    "time_df = time.generate_df()\n",
    "\n",
    "# -- å¹´é »æ™‚é–“ï¼ˆåªå–æ¯å¹´ 12 æœˆï¼‰\n",
    "year_dates = [datetime(year, 12, 1) for year in range(start_time, end_time + 1)]\n",
    "year_df = pd.DataFrame(year_dates, columns=[\"date\"])\n",
    "year_df[\"date\"] = year_df[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "#è¿‘3æœˆç´¯è¨ˆç‡Ÿæ”¶æˆé•·ç‡ r25\n",
    "revenue_instance = REVENUE(year_df)\n",
    "revenue_result_df = revenue_instance.generate_df('r25').reset_index(drop=True)\n",
    "\n",
    "revenue_result_df['year'] = pd.to_datetime(revenue_result_df['mdate']).dt.year\n",
    "revenue_result_df['month'] = pd.to_datetime(revenue_result_df['mdate']).dt.month\n",
    "revenue_result_df['quarter'] = ((revenue_result_df['month'] - 1) // 3) + 1\n",
    "\n",
    "# åªå–å­£åº•æœˆä»½ï¼š3æœˆ, 6æœˆ, 9æœˆ, 12æœˆ\n",
    "season_end = revenue_result_df[revenue_result_df['month'].isin([3, 6, 9, 12])]\n",
    "\n",
    "# å»ºç«‹ key çµ¦å­£è³‡æ–™åš merge\n",
    "season_end = season_end[['coid', 'year', 'quarter', 'r25']].rename(columns={'r25': 'ç‡Ÿæ”¶ YoY'})\n",
    "\n",
    "##ç‡Ÿæ”¶YOY\n",
    "panel_df['ç‡Ÿæ”¶ YoY'] = panel_df.merge(season_end, on=['coid', 'year', 'quarter'], how='left')['ç‡Ÿæ”¶ YoY_y']\n",
    "\n",
    "reserve_instance = RESERVE(year_df)\n",
    "reserve_result_df = reserve_instance.generate_df('0170')\n",
    "\n",
    "reserve_result_df['year'] = pd.to_datetime(reserve_result_df['mdate']).dt.year\n",
    "reserve_result_df['month'] = pd.to_datetime(reserve_result_df['mdate']).dt.month\n",
    "reserve_result_df['quarter'] = ((reserve_result_df['month'] - 1) // 3) + 1\n",
    "\n",
    "reserve_0170 = reserve_result_df.copy()\n",
    "\n",
    "# å»ºç«‹å¹´+å­£æ¬„ä½ä»¥ä¾¿æ’åºèˆ‡å¯è¦–åŒ–\n",
    "reserve_0170['year_quarter'] = reserve_0170['year'].astype(str) + 'Q' + reserve_0170['quarter'].astype(str)\n",
    "\n",
    "# ä¾ coid èˆ‡å­£åº¦æ’åºå¾Œè¨ˆç®— YoYï¼ˆå¹´å¢ç‡ï¼‰\n",
    "reserve_0170['acc_value_yoy'] = (\n",
    "    reserve_0170.sort_values(['coid', 'year', 'quarter'])\n",
    "           .groupby('coid')['acc_value']\n",
    "           .pct_change(periods=4, fill_method=None)  # YoY = åŒå­£å‰ä¸€å¹´\n",
    ")\n",
    "\n",
    "# é¸æ“‡é¡¯ç¤ºçµæœï¼ˆå¦‚è¦ä¿ç•™å…¶ä»–æ¬„ä½ä¹Ÿå¯ä»¥ï¼‰\n",
    "reserve_0170_result = reserve_0170[['coid', 'year', 'quarter', 'acc_value', 'acc_value_yoy']]\n",
    "reserve_season_end = reserve_0170_result[['coid', 'year', 'quarter', 'acc_value', 'acc_value_yoy']].rename(columns={'acc_value_yoy': 'å­˜è²¨ YoY'})\n",
    "##å­˜è²¨YOY\n",
    "panel_df['å­˜è²¨ YoY'] = panel_df.merge(reserve_season_end, on=['coid', 'year', 'quarter'], how='left')['å­˜è²¨ YoY_y']\n",
    "\n",
    "gm_instance = GM(year_df)\n",
    "gm_result_df = gm_instance.generate_df('R105')\n",
    "\n",
    "gm_result_df['year'] = pd.to_datetime(gm_result_df['mdate']).dt.year\n",
    "gm_result_df['month'] = pd.to_datetime(gm_result_df['mdate']).dt.month\n",
    "gm_result_df['quarter'] = ((gm_result_df['month'] - 1) // 3) + 1\n",
    "\n",
    "gm_r105 = gm_result_df.copy()\n",
    "\n",
    "# å»ºç«‹å¹´+å­£æ¬„ä½ä»¥ä¾¿æ’åºèˆ‡å¯è¦–åŒ–\n",
    "gm_r105['year_quarter'] = gm_r105['year'].astype(str) + 'Q' + gm_r105['quarter'].astype(str)\n",
    "gm_season_end = gm_r105[['coid', 'year', 'quarter', 'acc_value']].rename(columns={'acc_value': 'æ¯›åˆ©ç‡'})\n",
    "##æ¯›åˆ©ç‡\n",
    "panel_df['æ¯›åˆ©ç‡'] = panel_df.merge(gm_season_end, on=['coid', 'year', 'quarter'], how='left')['æ¯›åˆ©ç‡_y']\n",
    "\n",
    "opm_instance = OPM(year_df)\n",
    "opm_result_df = opm_instance.generate_df('R106')\n",
    "\n",
    "opm_result_df['year'] = pd.to_datetime(opm_result_df['mdate']).dt.year\n",
    "opm_result_df['month'] = pd.to_datetime(opm_result_df['mdate']).dt.month\n",
    "opm_result_df['quarter'] = ((opm_result_df['month'] - 1) // 3) + 1\n",
    "\n",
    "opm_r106 = opm_result_df.copy()\n",
    "\n",
    "# å»ºç«‹å¹´+å­£æ¬„ä½ä»¥ä¾¿æ’åºèˆ‡å¯è¦–åŒ–\n",
    "opm_r106['year_quarter'] = opm_r106['year'].astype(str) + 'Q' + opm_r106['quarter'].astype(str)\n",
    "opm_season_end = opm_r106[['coid', 'year', 'quarter', 'acc_value']].rename(columns={'acc_value': 'ç‡Ÿæ¥­åˆ©ç›Šç‡'})\n",
    "##ç‡Ÿæ¥­åˆ©ç›Šç‡\n",
    "panel_df['ç‡Ÿæ¥­åˆ©ç›Šç‡'] = panel_df.merge(opm_season_end, on=['coid', 'year', 'quarter'], how='left')['ç‡Ÿæ¥­åˆ©ç›Šç‡_y']\n",
    "\n",
    "money_instance = MONEY(year_df)\n",
    "money_result_df = money_instance.generate_df('7210')\n",
    "\n",
    "money_result_df['year'] = pd.to_datetime(money_result_df['mdate']).dt.year\n",
    "money_result_df['month'] = pd.to_datetime(money_result_df['mdate']).dt.month\n",
    "money_result_df['quarter'] = ((money_result_df['month'] - 1) // 3) + 1\n",
    "\n",
    "money_7210 = money_result_df.copy()\n",
    "\n",
    "# å»ºç«‹å¹´+å­£æ¬„ä½ä»¥ä¾¿æ’åºèˆ‡å¯è¦–åŒ–\n",
    "money_7210['year_quarter'] = money_7210['year'].astype(str) + 'Q' + money_7210['quarter'].astype(str)\n",
    "money_season_end = money_7210[['coid', 'year', 'quarter', 'acc_value']].rename(columns={'acc_value': 'ç‡Ÿæ¥­ç¾é‡‘æµ'})\n",
    "##ç‡Ÿæ¥­ç¾é‡‘æµ\n",
    "panel_df['ç‡Ÿæ¥­ç¾é‡‘æµ'] = panel_df.merge(money_season_end, on=['coid', 'year', 'quarter'], how='left')['ç‡Ÿæ¥­ç¾é‡‘æµ_y']\n",
    "panel_df['ç‡Ÿæ¥­ç¾é‡‘æµ'] = panel_df['ç‡Ÿæ¥­ç¾é‡‘æµ']*1000\n",
    "\n",
    "panel_cleaned = panel_df.dropna(axis=1, how='all')\n",
    "\n",
    "# save_path_2 = Path.cwd() / \"goodinfo\" / f\"{save_industry}.csv\"\n",
    "# panel_cleaned.to_csv(save_path_2, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combind goodinfo 2011å¹´å‰è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_financial(file, coid):\n",
    "    xls = pd.ExcelFile(file)\n",
    "\n",
    "    time_index = []\n",
    "    for y in range(2006, 2011):  # 2006 ~ 2010\n",
    "        for q in range(1, 5):\n",
    "            if (y == 2006 and q < 3) or (y == 2010 and q > 4):\n",
    "                continue\n",
    "            time_index.append(f\"{y}Q{q}\")\n",
    "    time_df = pd.DataFrame({\"ymq\": time_index})\n",
    "    time_df[\"year\"] = time_df[\"ymq\"].str[:4].astype(int)\n",
    "    time_df[\"quarter\"] = time_df[\"ymq\"].str[-1].astype(int)\n",
    "    time_df[\"coid\"] = coid\n",
    "\n",
    "    # --- income sheet ---\n",
    "    income = pd.read_excel(xls, \"income\", index_col=0)\n",
    "    income = income.loc[income.index.isin([\"ç‡Ÿæ¥­æ”¶å…¥\", \"ç‡Ÿæ¥­æ¯›åˆ©\", \"ç‡Ÿæ¥­åˆ©ç›Š\"])]\n",
    "\n",
    "    # æ‹†å‡ºé‡‘é¡èˆ‡ %\n",
    "    amount_cols = [c for c in income.columns if re.match(r\"\\d{4}Q[1-4]_é‡‘é¡\", c)]\n",
    "    percent_cols = [c for c in income.columns if re.match(r\"\\d{4}Q[1-4]_ï¼…\", c)]\n",
    "\n",
    "    # ç‡Ÿæ¥­æ”¶å…¥é‡‘é¡ â†’ å¹´å¢ç‡\n",
    "    revenue = income.loc[\"ç‡Ÿæ¥­æ”¶å…¥\", amount_cols].astype(float)\n",
    "    revenue.index = revenue.index.str.replace(\"_é‡‘é¡\", \"\", regex=False)\n",
    "    revenue = revenue.sort_index()\n",
    "    prev = revenue.shift(4)\n",
    "    yoy = (revenue / prev - 1) * 100\n",
    "    yoy[(prev <= 0) | (prev.isna())] = pd.NA\n",
    "    yoy.name = \"ç‡Ÿæ”¶ YoY\"\n",
    "\n",
    "    # ç‡Ÿæ¥­æ¯›åˆ©ç‡ (%)\n",
    "    gross_margin = pd.to_numeric(income.loc[\"ç‡Ÿæ¥­æ¯›åˆ©\", percent_cols], errors='coerce')\n",
    "    gross_margin.index = gross_margin.index.str.replace(\"_ï¼…\", \"\", regex=False)\n",
    "    gross_margin.name = \"æ¯›åˆ©ç‡\"\n",
    "\n",
    "    # ç‡Ÿæ¥­åˆ©ç›Šç‡ (%)\n",
    "    op_margin = pd.to_numeric(income.loc[\"ç‡Ÿæ¥­åˆ©ç›Š\", percent_cols], errors='coerce')\n",
    "    op_margin.index = op_margin.index.str.replace(\"_ï¼…\", \"\", regex=False)\n",
    "    op_margin.name = \"ç‡Ÿæ¥­åˆ©ç›Šç‡\"\n",
    "\n",
    "    income_df = pd.concat([yoy, gross_margin, op_margin], axis=1).reset_index()\n",
    "    income_df = income_df.rename(columns={\"index\": \"ymq\"})\n",
    "\n",
    "    # --- balance_sheet sheet ---\n",
    "    bs = pd.read_excel(xls, \"balance_sheet\", index_col=0)\n",
    "    bs = bs.loc[bs.index == \"å­˜è²¨\"]\n",
    "    # åªå–é‡‘é¡æ¬„ä½\n",
    "    inv_amount_cols = [c for c in bs.columns if re.match(r\"\\d{4}Q[1-4]_é‡‘é¡\", c)]\n",
    "    inventory = bs.loc[\"å­˜è²¨\", inv_amount_cols].astype(float)\n",
    "    # æ•´ç† index (å»æ‰ \"_é‡‘é¡\")\n",
    "    inventory.index = inventory.index.str.replace(\"_é‡‘é¡\", \"\", regex=False)\n",
    "    inventory = inventory.sort_index()\n",
    "    # è¨ˆç®— YoYï¼ˆé‡åˆ°å»å¹´åŒæœŸ <= 0 æˆ– NaN â†’ NaNï¼‰\n",
    "    prev_inv = inventory.shift(4)\n",
    "    inventory_yoy = (inventory / prev_inv - 1) * 100\n",
    "    inventory_yoy[(prev_inv <= 0) | (prev_inv.isna())] = pd.NA\n",
    "    inventory_yoy.name = \"å­˜è²¨ YoY\"\n",
    "    # è½‰æˆ DataFrame\n",
    "    inventory_df = inventory_yoy.reset_index().rename(columns={\"index\": \"ymq\"})\n",
    "\n",
    "\n",
    "    # --- cash_flow sheet ---\n",
    "    cf = pd.read_excel(xls, \"cash_flow\", index_col=0)\n",
    "    cf = cf.loc[cf.index == \"ç‡Ÿæ¥­æ´»å‹•ä¹‹æ·¨ç¾é‡‘æµå…¥(å‡º)\"]\n",
    "    cf = cf.T.reset_index().rename(columns={\"index\": \"ymq\", \"ç‡Ÿæ¥­æ´»å‹•ä¹‹æ·¨ç¾é‡‘æµå…¥(å‡º)\": \"ç‡Ÿæ¥­ç¾é‡‘æµ\"})\n",
    "\n",
    "    # --- merge ---\n",
    "    combined = time_df.merge(income_df, on=\"ymq\", how=\"left\")\n",
    "    combined = combined.merge(inventory_df, on=\"ymq\", how=\"left\")\n",
    "    combined = combined.merge(cf, on=\"ymq\", how=\"left\")\n",
    "\n",
    "    return combined[[\"coid\", \"year\", \"quarter\", \"ç‡Ÿæ”¶ YoY\", \"å­˜è²¨ YoY\", \"æ¯›åˆ©ç‡\", \"ç‡Ÿæ¥­åˆ©ç›Šç‡\", \"ç‡Ÿæ¥­ç¾é‡‘æµ\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coids = [\"2330\", \"2454\", \"3034\", \"8299\", \"2379\"]\n",
    "\n",
    "all_panels = []\n",
    "\n",
    "for coid in coids:\n",
    "    file = f\"{stock_path}/{coid}/{coid}.xlsx\"\n",
    "    df = reshape_financial(file, coid)\n",
    "    all_panels.append(df)\n",
    "\n",
    "# åˆä½µæ‰€æœ‰è‚¡ç¥¨\n",
    "panel_all = pd.concat(all_panels, ignore_index=True)\n",
    "\n",
    "# å°‡ panel_all çš„ coid è½‰æˆ int\n",
    "panel_all[\"coid\"] = panel_all[\"coid\"].astype(int)\n",
    "\n",
    "# å°‡ panel_all çš„ ç‡Ÿæ¥­ç¾é‡‘æµ è½‰æˆ floatï¼Œé‡åˆ°éæ•¸å­—ç”¨ NaN\n",
    "panel_all[\"ç‡Ÿæ¥­ç¾é‡‘æµ\"] = pd.to_numeric(panel_all[\"ç‡Ÿæ¥­ç¾é‡‘æµ\"], errors=\"coerce\")\n",
    "\n",
    "industry = pd.read_csv(f\"/home/jovyan/business-cycle/goodinfo/{save_industry}.csv\")\n",
    "\n",
    "full_panel = pd.concat([panel_all, industry], ignore_index=True)\n",
    "\n",
    "panel_cleaned_2 = full_panel.sort_values(by=[\"coid\", \"year\", \"quarter\"]).reset_index(drop=True)\n",
    "\n",
    "# save_path_3 = Path.cwd() / \"goodinfo\" / f\"{save_industry_2}.csv\"\n",
    "# panel_cleaned_2.to_csv(save_path_3, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å°‡ä½¿ç”¨çš„è²¡å ±featuresæ ¹æ“šrolling_percentileåŠpcaè¨ˆç®—å‡ºæ™¯æ°£åˆ†æ•¸ï¼Œä¸¦å°‡æ—¥æœŸå»¶å¾Œ(ç¬¦åˆè²¡å ±å…¬ä½ˆæ—¥æœŸ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ç‡Ÿæ”¶ YoY', 'å­˜è²¨ YoY', 'æ¯›åˆ©ç‡', 'ç‡Ÿæ¥­åˆ©ç›Šç‡', 'ç‡Ÿæ¥­ç¾é‡‘æµ']\n",
    "\n",
    "# å°‡ inf è½‰æˆ NaN\n",
    "panel_cleaned_2.loc[:, features] = panel_cleaned_2.loc[:, features].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# ç§»é™¤å«æœ‰ NaN çš„ã€Œè©²ç­†è³‡æ–™ã€ï¼ˆå³ï¼šæŸå€‹è‚¡æŸå­£ï¼‰\n",
    "panel_cleaned_2 = panel_cleaned_2.dropna(subset=features)\n",
    "\n",
    "for col in ['æ¯›åˆ©ç‡', 'ç‡Ÿæ¥­åˆ©ç›Šç‡']:\n",
    "    panel_cleaned_2 = panel_cleaned_2[\n",
    "        (panel_cleaned_2[col] > -100) & (panel_cleaned_2[col] < 100)\n",
    "    ]\n",
    "    \n",
    "panel_cleaned_2['ç‡Ÿæ”¶ YoY'] = panel_cleaned_2['ç‡Ÿæ”¶ YoY'].clip(lower=-100, upper=300)\n",
    "\n",
    "panel_cleaned_2['date'] = pd.PeriodIndex.from_fields(\n",
    "    year=panel_cleaned_2['year'],\n",
    "    quarter=panel_cleaned_2['quarter'],\n",
    "    freq='Q'\n",
    ").to_timestamp()\n",
    "\n",
    "indicators = ['ç‡Ÿæ”¶ YoY', 'å­˜è²¨ YoY', 'æ¯›åˆ©ç‡', 'ç‡Ÿæ¥­åˆ©ç›Šç‡', 'ç‡Ÿæ¥­ç¾é‡‘æµ']\n",
    "\n",
    "def rolling_percentile(group):\n",
    "    group = group.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "    coid = group['coid'].iloc[0]\n",
    "    result = group[['year', 'quarter', 'date']].iloc[12:].copy()\n",
    "    result['coid'] = coid\n",
    "\n",
    "    for indicator in indicators:\n",
    "        scores = []\n",
    "        for i in range(12, len(group)):\n",
    "            window = group.iloc[i-12:i]\n",
    "            current = group.iloc[i][indicator]\n",
    "\n",
    "            # è¨ˆç®—åˆ†ä½æ•¸\n",
    "            percentile = (window[indicator] < current).mean()\n",
    "            scores.append(percentile)\n",
    "\n",
    "        # å°æ‡‰åˆ° 1~5 åˆ†æ•¸\n",
    "        bins = [-0.01, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "        labels = [1, 2, 3, 4, 5]\n",
    "        result[indicator + '_percentile'] = scores\n",
    "        result[indicator + '_score'] = pd.cut(scores, bins=bins, labels=labels).astype(int)\n",
    "\n",
    "    return result\n",
    "\n",
    "results = []\n",
    "for coid, group in panel_cleaned_2.groupby('coid'):\n",
    "    df = rolling_percentile(group)\n",
    "    df['coid'] = coid  # æ‰‹å‹•è£œå› coid\n",
    "    results.append(df)\n",
    "\n",
    "df_out = pd.concat(results).reset_index(drop=True)\n",
    "\n",
    "features_2 = ['ç‡Ÿæ”¶ YoY_score', 'å­˜è²¨ YoY_score', 'æ¯›åˆ©ç‡_score', 'ç‡Ÿæ¥­åˆ©ç›Šç‡_score', 'ç‡Ÿæ¥­ç¾é‡‘æµ_score']\n",
    "X = df_out[features_2]\n",
    "\n",
    "# PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# å»ºç«‹ä¸»æˆåˆ†åç¨±\n",
    "pc_names = [f'PC{i+1}' for i in range(pca.components_.shape[0])]\n",
    "\n",
    "# å»ºç«‹ DataFrame é¡¯ç¤ºæ¯å€‹ä¸»æˆåˆ†çš„ loading\n",
    "loadings_df = pd.DataFrame(pca.components_, columns=features, index=pc_names)\n",
    "\n",
    "def compute_prosperity_score(df_out, X_pca, pca, n_components=1):\n",
    "    \"\"\"\n",
    "    æ ¹æ“šå‰ n å€‹ä¸»æˆåˆ†è¨ˆç®—ç¶œåˆæ™¯æ°£å¾—åˆ†ï¼Œä¸¦è¼¸å‡ºå¯¬æ ¼å¼è¡¨æ ¼ã€‚\n",
    "    \n",
    "    åƒæ•¸ï¼š\n",
    "        df_out: åŸå§‹è³‡æ–™ï¼ˆåŒ…å« year, quarter, coidï¼‰\n",
    "        X_pca: PCA è½‰æ›å¾Œçš„è³‡æ–™ï¼ˆé€šå¸¸æ˜¯ pca.transform(X) çš„çµæœï¼‰\n",
    "        pca: å·²æ“¬åˆçš„ PCA æ¨¡å‹\n",
    "        n_components: è¦ä½¿ç”¨å¹¾å€‹ä¸»æˆåˆ†è¨ˆç®—æ™¯æ°£åˆ†æ•¸ï¼ˆé è¨­ç‚º 1ï¼‰\n",
    "    \n",
    "    å›å‚³ï¼š\n",
    "        df_pivot: å¯¬æ ¼å¼è³‡æ–™ï¼Œå«æ¯å®¶å…¬å¸èˆ‡ç”¢æ¥­å¹³å‡çš„æ™¯æ°£å¾—åˆ†\n",
    "    \"\"\"\n",
    "    # é™åˆ¶æœ€å¤§ä¸èƒ½è¶…éä¸»æˆåˆ†æ•¸\n",
    "    n_components = min(n_components, X_pca.shape[1])\n",
    "\n",
    "    # å–å‡ºå‰ n å€‹ä¸»æˆåˆ†çš„åŠ æ¬Šå¹³å‡ï¼ˆä¾ç…§è§£é‡‹è®Šç•°æ¯”ä¾‹ï¼‰\n",
    "    weights = pca.explained_variance_ratio_[:n_components]\n",
    "    weights = weights / weights.sum()  # è®“æ¬Šé‡ç¸½å’Œç‚º 1\n",
    "    weighted_score = (X_pca[:, :n_components] * weights).sum(axis=1)\n",
    "\n",
    "    # åŠ å…¥æ™¯æ°£å¾—åˆ†æ¬„ä½\n",
    "    df_out = df_out.copy()\n",
    "    df_out['ç¶œåˆæ™¯æ°£å¾—åˆ†'] = weighted_score\n",
    "\n",
    "    # å»ºç«‹æ™‚é–“æ¬„ä½\n",
    "    df_out['Date'] = df_out['year'].astype(str) + '-Q' + df_out['quarter'].astype(str)\n",
    "\n",
    "    # å¯¬æ ¼å¼è½‰æ›\n",
    "    df_pivot = df_out.pivot(index='Date', columns='coid', values='ç¶œåˆæ™¯æ°£å¾—åˆ†')\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "\n",
    "    # åŠ ç¸½ç”¢æ¥­å¹³å‡æ™¯æ°£åˆ†æ•¸\n",
    "    df_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'] = df_pivot.drop(columns=['Date']).mean(axis=1)\n",
    "\n",
    "    return df_pivot\n",
    "\n",
    "\n",
    "df_pivot = compute_prosperity_score(df_out, X_pca, pca, n_components=3)\n",
    "\n",
    "# å‡è¨­ df_pivot['Date'] é•·é€™æ¨£: '2012-Q1' æ ¼å¼\n",
    "quarter_to_month = {\"Q1\": \"03\", \"Q2\": \"06\", \"Q3\": \"09\", \"Q4\": \"12\"}\n",
    "\n",
    "# è½‰æˆæœˆä»½èµ·å§‹æ—¥ï¼ˆQ1 â†’ 03æœˆ1æ—¥ï¼‰\n",
    "df_pivot[\"base_date\"] = df_pivot[\"Date\"].apply(\n",
    "    lambda x: pd.to_datetime(f\"{x[:4]}-{quarter_to_month[x[-2:]]}-01\")\n",
    ")\n",
    "\n",
    "# å»¶å¾Œå…©å€‹æœˆ\n",
    "df_pivot[\"date_shifted\"] = df_pivot[\"base_date\"] + pd.DateOffset(months=2)\n",
    "\n",
    "\n",
    "quantile_pivot = df_pivot.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¨ˆç®—åˆ†ä½æ•¸ä¸¦çµ¦äºˆå°æ‡‰ç‡ˆè™ŸåŠåˆ†æ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨ˆç®—å››åˆ†ä½\n",
    "q20 = df_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'].quantile(0.2)\n",
    "q40 = df_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'].quantile(0.4)\n",
    "q60 = df_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'].quantile(0.6)\n",
    "q80 = df_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'].quantile(0.8)\n",
    "\n",
    "# å°æ‡‰ç‡ˆè™Ÿåˆ†é¡é‚è¼¯\n",
    "def assign_five_lights(score):\n",
    "    if score >= q80:\n",
    "        return 'ğŸ”´ éå¸¸ç†±'\n",
    "    elif score >= q60:\n",
    "        return 'ğŸŸ  åç†±'\n",
    "    elif score >= q40:\n",
    "        return 'ğŸŸ¡ ç©©å®š'\n",
    "    elif score >= q20:\n",
    "        return 'ğŸŸ¢ åå†·'\n",
    "    else:\n",
    "        return 'ğŸ”µ éå¸¸å†·'\n",
    "\n",
    "# æ–°å¢ç‡ˆè™Ÿæ¬„ä½\n",
    "quantile_pivot['ç‡ˆè™Ÿ'] = quantile_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'].apply(assign_five_lights)\n",
    "\n",
    "save_data = quantile_pivot[['date_shifted','ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸','ç‡ˆè™Ÿ']].copy()\n",
    "\n",
    "save_data['ç‡ˆè™Ÿåˆ†æ•¸'] = save_data['ç‡ˆè™Ÿ'].map({\n",
    "    'ğŸ”´ éå¸¸ç†±': 5,\n",
    "    'ğŸŸ  åç†±': 4,\n",
    "    'ğŸŸ¡ ç©©å®š': 3,\n",
    "    'ğŸŸ¢ åå†·': 2,\n",
    "    'ğŸ”µ éå¸¸å†·': 1\n",
    "})\n",
    "\n",
    "daily_rows = []\n",
    "\n",
    "for _, row in save_data.iterrows():\n",
    "    start_date = pd.to_datetime(row['date_shifted'])\n",
    "    end_date = (start_date + pd.offsets.MonthEnd(0))  # æœ¬æœˆæœ€å¾Œä¸€å¤©\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "    expanded = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'ç‡ˆè™Ÿ': row['ç‡ˆè™Ÿ'],\n",
    "        'ç‡ˆè™Ÿåˆ†æ•¸': row['ç‡ˆè™Ÿåˆ†æ•¸'],\n",
    "        'date_shifted': row['date_shifted'],\n",
    "        'ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸': row['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸']\n",
    "    })\n",
    "\n",
    "    daily_rows.append(expanded)\n",
    "\n",
    "# 4. åˆä½µæ‰€æœ‰æ¯æ—¥è³‡æ–™\n",
    "daily_data = pd.concat(daily_rows, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# å‡è¨­ monthly_data æ˜¯ä½ æä¾›çš„ DataFrameï¼ŒåŒ…å« 'date_shifted', 'ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸', 'ç‡ˆè™Ÿ'\n",
    "daily_data['end_date'] = daily_data['date_shifted'].shift(-1) - pd.Timedelta(days=1)\n",
    "daily_data.loc[daily_data['end_date'].isna(), 'end_date'] = pd.Timestamp('2025-04-30')  # æˆ– today()\n",
    "\n",
    "# å»ºç«‹ç‡ˆè™Ÿå°æ‡‰åˆ†æ•¸\n",
    "light_score_map = {\n",
    "    'ğŸ”´ éå¸¸ç†±': 5,\n",
    "    'ğŸŸ  åç†±': 4,\n",
    "    'ğŸŸ¡ ç©©å®š': 3,\n",
    "    'ğŸŸ¢ åå†·': 2,\n",
    "    'ğŸ”µ éå¸¸å†·': 1\n",
    "}\n",
    "daily_data['ç‡ˆè™Ÿåˆ†æ•¸'] = daily_data['ç‡ˆè™Ÿ'].map(light_score_map)\n",
    "\n",
    "# å±•å¹³ç‚ºæ¯æ—¥è³‡æ–™\n",
    "all_rows = []\n",
    "for _, row in daily_data.iterrows():\n",
    "    daily_dates = pd.date_range(start=row['date_shifted'], end=row['end_date'], freq='D')\n",
    "    df_daily = pd.DataFrame({\n",
    "        'date': daily_dates,\n",
    "        'date_shifted': row['date_shifted'],\n",
    "        'ç‡ˆè™Ÿ': row['ç‡ˆè™Ÿ'],\n",
    "        'ç‡ˆè™Ÿåˆ†æ•¸': row['ç‡ˆè™Ÿåˆ†æ•¸'],\n",
    "        'ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸': row['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸']\n",
    "    })\n",
    "    all_rows.append(df_daily)\n",
    "\n",
    "daily_full = pd.concat(all_rows).reset_index(drop=True)\n",
    "\n",
    "daily_full_save = daily_full[['date','ç‡ˆè™Ÿåˆ†æ•¸']]\n",
    "\n",
    "# save_path_4 = Path.cwd() / f\"{save_signal_lights}\" / f\"{industry_composition}\" / f\"{save_industry}.csv\"\n",
    "# daily_full_save.to_csv(save_path_4, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç•«å‡ºç”¢æ¥­æŒ‡æ•¸èˆ‡æ™¯æ°£ç‡ˆè™Ÿçš„å°ç…§åœ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nutrlink.helper import get_ohlcv\n",
    "price_df = get_ohlcv(\n",
    "        nl,\n",
    "        tickers=industry_code,\n",
    "        start=\"2012-01-01\",\n",
    "        end=\"2025-05-31\",\n",
    "        adjusted=True,\n",
    "    )\n",
    "\n",
    "price_df = price_df.reset_index()\n",
    "price_df['datetime'] = pd.to_datetime(price_df['datetime'])  # ç¢ºä¿æ˜¯ datetime æ ¼å¼\n",
    "price_df = price_df.set_index(['ticker', 'datetime']).sort_index()\n",
    "\n",
    "# ä¾ ticker åˆ†çµ„å†è½‰æ›æœˆè³‡æ–™\n",
    "monthly = (\n",
    "    price_df.groupby(level='ticker')\n",
    "            .resample('ME', level='datetime')\n",
    "            .agg({\n",
    "                'open': 'first',\n",
    "                'high': 'max',\n",
    "                'low': 'min',\n",
    "                'close': 'last',\n",
    "                'volume': 'sum'\n",
    "                })\n",
    "            .reset_index()\n",
    ")\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# é¡è‰²å°æ‡‰è¡¨\n",
    "color_map = {\n",
    "    'ğŸ”´ éå¸¸ç†±': 'red',\n",
    "    'ğŸŸ  åç†±': 'orange',\n",
    "    'ğŸŸ¡ ç©©å®š': 'gold',\n",
    "    'ğŸŸ¢ åå†·': 'green',\n",
    "    'ğŸ”µ éå¸¸å†·': 'blue'\n",
    "}\n",
    "\n",
    "marker_colors = quantile_pivot['ç‡ˆè™Ÿ'].map(color_map)\n",
    "\n",
    "# å»ºç«‹åœ–\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=1,\n",
    "    specs=[[{\"secondary_y\": True}]],\n",
    "    subplot_titles=(\"ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸ vs æœˆæ”¶ç›¤åƒ¹\",)\n",
    ")\n",
    "\n",
    "# åŠ å…¥æ™¯æ°£åˆ†æ•¸ï¼ˆä¸» y è»¸ï¼‰+ ç‡ˆè™Ÿæ¨™è‰²\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=quantile_pivot['date_shifted'],\n",
    "    y=quantile_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'],\n",
    "    mode='lines+markers',\n",
    "    name='ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸',\n",
    "    line=dict(color='black'),\n",
    "    marker=dict(color=marker_colors, size=10, symbol='circle'),\n",
    "    hovertemplate='æ—¥æœŸ: %{x|%Y-%m-%d}<br>æ™¯æ°£åˆ†æ•¸: %{y:.3f}<br>ç‡ˆè™Ÿ: %{text}',\n",
    "    text=quantile_pivot['ç‡ˆè™Ÿ']\n",
    "), row=1, col=1, secondary_y=False)\n",
    "\n",
    "# åŠ å…¥æœˆæ”¶ç›¤åƒ¹ï¼ˆå‰¯ y è»¸ï¼‰\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=monthly['datetime'],\n",
    "    y=monthly['close'],\n",
    "    mode='lines+markers',\n",
    "    name='æœˆæ”¶ç›¤åƒ¹',\n",
    "    line=dict(color='green'),\n",
    "    hovertemplate='æ—¥æœŸ: %{x|%Y-%m-%d}<br>æ”¶ç›¤åƒ¹: %{y:.2f} å…ƒ'\n",
    "), row=1, col=1, secondary_y=True)\n",
    "\n",
    "# Layout è¨­å®š\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    title_text=\"ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸èˆ‡æœˆæ”¶ç›¤åƒ¹ï¼ˆåŒåœ–é›™ Y è»¸ï¼‰\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"æ—¥æœŸ\")\n",
    "fig.update_yaxes(title_text=\"æ™¯æ°£åˆ†æ•¸\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"æ”¶ç›¤åƒ¹ (å…ƒ)\", secondary_y=True)\n",
    "\n",
    "pio.renderers.default = 'browser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
