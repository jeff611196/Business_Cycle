#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Jun 10 15:06:23 2025

@author: jeff
"""

import numpy as np
import pandas as pd    
import json
import itertools  
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA  
from datetime import datetime
from nutrlink import NutrLink
nl = NutrLink(url="https://dev-api.ddt-dst.cc/nutrients/station")


def INDUSTRY():

    res = nl.get("tw_industry")
    filtered = res[res['ticker'].str.len() == 4]
    selected_columns = ['ticker', 'twse_ind']
    use_df = filtered[selected_columns]
    use_df = use_df.reset_index(drop=True)
    
    # total_data_1 = pd.read_parquet(
    #     f"{PLUMBER_HOST}tej/stock/twn/aind",
    #     storage_options={
    #         "gcp-token": json.dumps(token)
    #     },
    # )

    # filtered = total_data_1[total_data_1['coid'].str.len() == 4]
    # selected_columns = ['coid', 'tejind4_c']
    # use_df = filtered[selected_columns]
    # use_df = use_df.reset_index(drop=True)

    return use_df

class use_time:
    def __init__(self, start_year, end_year):
        self.start_year = start_year+1
        self.end_year = end_year

    def generate_df(self):
        dates = [datetime(year, 12, 1).strftime('%Y-%m-%d') for year in range(self.start_year, self.end_year + 1)]
        df = pd.DataFrame(dates, columns=['date'])
        
        # months = [3, 6, 9, 12]  # æ¯å­£çš„ç¬¬ä¸€å¤©
        # dates = [
        #     datetime(year, month, 1).strftime('%Y-%m-%d')
        #     for year in range(self.start_year, self.end_year + 1)
        #     for month in months
        # ]
        # df = pd.DataFrame(dates, columns=['date'])
        return df

class REVENUE:
    def __init__(self, time_df):
        self.time = pd.to_datetime(time_df['date'])
        self.time = self.time.dt.tz_localize("UTC")
        self.time_ori = time_df['date'].astype(str)

    def generate_df(self, code):
        
        start_date = self.time.min()
        end_date = self.time.max()

        filters = [
            ("mdate", ">=", start_date),
            ("mdate", "<=", end_date),
            ]

        read_data = nl.get("tej_stock_twn_asale", filters=filters)
        revenue_table = read_data.loc[:, ['coid', 'mdate', code]]
        revenue_filtered = revenue_table.loc[
            (revenue_table['coid'].str.len() == 4)
            ]


        # all_data = []
        # for date in self.time_ori:
        #     read_data = pd.read_parquet(
        #         f"{PLUMBER_HOST}tej/stock/twn/asale",
        #         storage_options={
        #             "gcp-token": json.dumps(token),
        #             "start-date": date,
        #             "end-date": date
        #             },
        #         )

        #     revenue_table_ori = read_data.loc[:, ['coid', 'mdate', 'd0007']]
        #     revenue_filtered_ori = revenue_table_ori[revenue_table_ori['coid'].str.len() == 4]
        #     all_data.append(revenue_filtered_ori)

        # final_df = pd.concat(all_data, ignore_index=True)
        return revenue_filtered
    
class RESERVE():
    def __init__(self, time_df):
        self.time = pd.to_datetime(time_df['date'])
        self.time = self.time.dt.tz_localize("UTC")
        self.time_ori = time_df['date'].astype(str)
        
    def generate_df(self, code):
        
        start_date = self.time.min()
        end_date = self.time.max()
        
        filters = [
            ("mdate", ">=", start_date),
            ("mdate", "<=", end_date),
            ]
        
        res = nl.get("tej_financial_statements_twn_aim1aq", filters=filters)
        reserve_table = res[res['acc_code'] == code]
        reserve_filtered = reserve_table.loc[
            (reserve_table['coid'].str.len() == 4)
            ]
        
        return reserve_filtered
    
class GM():
    def __init__(self, time_df):
        self.time = pd.to_datetime(time_df['date'])
        self.time = self.time.dt.tz_localize("UTC")
        self.time_ori = time_df['date'].astype(str)
        
    def generate_df(self, code):
        
        start_date = self.time.min()
        end_date = self.time.max()
        
        filters = [
            ("mdate", ">=", start_date),
            ("mdate", "<=", end_date),
            ]
        
        res = nl.get("tej_financial_statements_twn_aim1aq", filters=filters)
        reserve_table = res[res['acc_code'] == code]
        reserve_filtered = reserve_table.loc[
            (reserve_table['coid'].str.len() == 4)
            ]
        
        return reserve_filtered
    
class OPM():
    def __init__(self, time_df):
        self.time = pd.to_datetime(time_df['date'])
        self.time = self.time.dt.tz_localize("UTC")
        self.time_ori = time_df['date'].astype(str)
        
    def generate_df(self, code):
        
        start_date = self.time.min()
        end_date = self.time.max()
        
        filters = [
            ("mdate", ">=", start_date),
            ("mdate", "<=", end_date),
            ]
        
        res = nl.get("tej_financial_statements_twn_aim1aq", filters=filters)
        reserve_table = res[res['acc_code'] == code]
        reserve_filtered = reserve_table.loc[
            (reserve_table['coid'].str.len() == 4)
            ]
        
        return reserve_filtered
    
class MONEY():
    def __init__(self, time_df):
        self.time = pd.to_datetime(time_df['date'])
        self.time = self.time.dt.tz_localize("UTC")
        self.time_ori = time_df['date'].astype(str)
        
    def generate_df(self, code):
        
        start_date = self.time.min()
        end_date = self.time.max()
        
        filters = [
            ("mdate", ">=", start_date),
            ("mdate", "<=", end_date),
            ]
        
        res = nl.get("tej_financial_statements_twn_aim1aq", filters=filters)
        reserve_table = res[res['acc_code'] == code]
        reserve_filtered = reserve_table.loc[
            (reserve_table['coid'].str.len() == 4)
            ]
        
        return reserve_filtered

industry = INDUSTRY()
industry['twse_ind'] = industry['twse_ind'].str.strip()
use_industry = 'è³‡è¨Šæœå‹™æ¥­'
use_stock = industry.loc[(industry['twse_ind'] == use_industry)]
use_stock = use_stock.reset_index(drop=True)

#å…ˆä½¿ç”¨ä»¥2011 Q1çš„å‰20å¤§å¸‚å€¼
start_date = datetime.fromisoformat("2011-03-01 00:00:00+00:00")

filters = [
    ("mdate", "==", start_date)
    ]

read_data = nl.get("tej_financial_statements_twn_aim1a", filters=filters)
market_value_table = read_data.iloc[np.where(read_data['acc_code'] == 'MV')[0],:]
market_value_filtered = market_value_table[market_value_table['coid'].str.len() == 4]

# è½‰æˆå­—ä¸²ä»¥é˜² coid/ticker è³‡æ–™å‹åˆ¥ä¸ä¸€è‡´
use_ticker_list = use_stock['ticker'].astype(str).tolist()

# ç¯©å‡ºåœ¨ use_stock ä¸­çš„å…¬å¸
market_value_selected = market_value_filtered[
    market_value_filtered['coid'].astype(str).isin(use_ticker_list)
].copy()

market_value_selected['coid'] = market_value_selected['coid'].astype(int)

# ç´¡ç¹”çº–ç¶­
# remove_tickers = [1402, 1434, 1303, 1455, 1710, 1409, 4414]
remove_tickers = []

# æ’é™¤ä¸éœ€è¦çš„ coid
final_mv = market_value_selected[~market_value_selected['coid'].isin(remove_tickers)].copy()

top_20_mv = final_mv.sort_values(by='acc_value', ascending=False)
top_20_mv = final_mv.sort_values(by='acc_value', ascending=False).head(5)
top_20_mv[['coid']].to_csv('/Users/jeff/Desktop/Business Cycle/top_k/top_5/electronic_distribution.csv', index=False)
top_20_mv = pd.read_csv('/Users/jeff/Desktop/Business Cycle/top_k/top_5/electronic_distribution.csv')

# å‡è¨­ top_20_mv æ˜¯æœ‰ coid çš„ DataFrame
coid_list = top_20_mv['coid'].astype(str).tolist()

# å‡è¨­ä½ åˆ†æçš„æ˜¯ 2018~2024 å¹´
years = list(range(2011, 2025))
quarters = [1, 2, 3, 4]

# å»ºç«‹æ‰€æœ‰ coid Ã— å¹´ Ã— å­£ çš„çµ„åˆ
all_combinations = list(itertools.product(coid_list, years, quarters))

# å»ºç«‹ DataFrame
panel_df = pd.DataFrame(all_combinations, columns=['coid', 'year', 'quarter'])

# æŒ‡æ¨™æ¬„ä½
indicators = [
    "ç‡Ÿæ”¶ YoY",
    "æ‡‰æ”¶å¸³æ¬¾é€±è½‰å¤©æ•¸",
    "å­˜è²¨ YoY",
    "å­˜è²¨é€±è½‰å¤©æ•¸",
    "æ¯›åˆ©ç‡",
    "ç‡Ÿæ¥­åˆ©ç›Šç‡",
    "ROE",
    "ç‡Ÿæ¥­ç¾é‡‘æµ",
    "ç¾é‡‘æ¯”",
    "çŸ­æœŸå€Ÿæ¬¾å æ¯”"
]

# åŠ ä¸Šç©ºæ¬„ä½ï¼ˆå…ˆå¡« NaNï¼‰
for col in indicators:
    panel_df[col] = pd.NA
    


#æ™‚é–“
start_time = 2010
end_time = 2024
time = use_time(start_time, end_time)
time_df = time.generate_df()

# -- å¹´é »æ™‚é–“ï¼ˆåªå–æ¯å¹´ 12 æœˆï¼‰
year_dates = [datetime(year, 12, 1) for year in range(start_time, end_time + 1)]
year_df = pd.DataFrame(year_dates, columns=["date"])
year_df["date"] = year_df["date"].dt.strftime("%Y-%m-%d")


#è¿‘3æœˆç´¯è¨ˆç‡Ÿæ”¶æˆé•·ç‡ r25
revenue_instance = REVENUE(year_df)
revenue_result_df = revenue_instance.generate_df('r25').reset_index(drop=True)

revenue_result_df['year'] = pd.to_datetime(revenue_result_df['mdate']).dt.year
revenue_result_df['month'] = pd.to_datetime(revenue_result_df['mdate']).dt.month
revenue_result_df['quarter'] = ((revenue_result_df['month'] - 1) // 3) + 1

# åªå–å­£åº•æœˆä»½ï¼š3æœˆ, 6æœˆ, 9æœˆ, 12æœˆ
season_end = revenue_result_df[revenue_result_df['month'].isin([3, 6, 9, 12])]

# å»ºç«‹ key çµ¦å­£è³‡æ–™åš merge
season_end = season_end[['coid', 'year', 'quarter', 'r25']].rename(columns={'r25': 'ç‡Ÿæ”¶ YoY'})

##ç‡Ÿæ”¶YOY
panel_df['ç‡Ÿæ”¶ YoY'] = panel_df.merge(season_end, on=['coid', 'year', 'quarter'], how='left')['ç‡Ÿæ”¶ YoY_y']

reserve_instance = RESERVE(year_df)
reserve_result_df = reserve_instance.generate_df('0170')

reserve_result_df['year'] = pd.to_datetime(reserve_result_df['mdate']).dt.year
reserve_result_df['month'] = pd.to_datetime(reserve_result_df['mdate']).dt.month
reserve_result_df['quarter'] = ((reserve_result_df['month'] - 1) // 3) + 1

reserve_0170 = reserve_result_df.copy()

# å»ºç«‹å¹´+å­£æ¬„ä½ä»¥ä¾¿æ’åºèˆ‡å¯è¦–åŒ–
reserve_0170['year_quarter'] = reserve_0170['year'].astype(str) + 'Q' + reserve_0170['quarter'].astype(str)

# ä¾ coid èˆ‡å­£åº¦æ’åºå¾Œè¨ˆç®— YoYï¼ˆå¹´å¢ç‡ï¼‰
reserve_0170['acc_value_yoy'] = (
    reserve_0170.sort_values(['coid', 'year', 'quarter'])
           .groupby('coid')['acc_value']
           .pct_change(periods=4, fill_method=None)  # YoY = åŒå­£å‰ä¸€å¹´
)

# é¸æ“‡é¡¯ç¤ºçµæœï¼ˆå¦‚è¦ä¿ç•™å…¶ä»–æ¬„ä½ä¹Ÿå¯ä»¥ï¼‰
reserve_0170_result = reserve_0170[['coid', 'year', 'quarter', 'acc_value', 'acc_value_yoy']]
reserve_season_end = reserve_0170_result[['coid', 'year', 'quarter', 'acc_value', 'acc_value_yoy']].rename(columns={'acc_value_yoy': 'å­˜è²¨ YoY'})
##å­˜è²¨YOY
panel_df['å­˜è²¨ YoY'] = panel_df.merge(reserve_season_end, on=['coid', 'year', 'quarter'], how='left')['å­˜è²¨ YoY_y']

gm_instance = GM(year_df)
gm_result_df = gm_instance.generate_df('R105')

gm_result_df['year'] = pd.to_datetime(gm_result_df['mdate']).dt.year
gm_result_df['month'] = pd.to_datetime(gm_result_df['mdate']).dt.month
gm_result_df['quarter'] = ((gm_result_df['month'] - 1) // 3) + 1

gm_r105 = gm_result_df.copy()

# å»ºç«‹å¹´+å­£æ¬„ä½ä»¥ä¾¿æ’åºèˆ‡å¯è¦–åŒ–
gm_r105['year_quarter'] = gm_r105['year'].astype(str) + 'Q' + gm_r105['quarter'].astype(str)
gm_season_end = gm_r105[['coid', 'year', 'quarter', 'acc_value']].rename(columns={'acc_value': 'æ¯›åˆ©ç‡'})
##æ¯›åˆ©ç‡
panel_df['æ¯›åˆ©ç‡'] = panel_df.merge(gm_season_end, on=['coid', 'year', 'quarter'], how='left')['æ¯›åˆ©ç‡_y']

opm_instance = OPM(year_df)
opm_result_df = opm_instance.generate_df('R106')

opm_result_df['year'] = pd.to_datetime(opm_result_df['mdate']).dt.year
opm_result_df['month'] = pd.to_datetime(opm_result_df['mdate']).dt.month
opm_result_df['quarter'] = ((opm_result_df['month'] - 1) // 3) + 1

opm_r106 = opm_result_df.copy()

# å»ºç«‹å¹´+å­£æ¬„ä½ä»¥ä¾¿æ’åºèˆ‡å¯è¦–åŒ–
opm_r106['year_quarter'] = opm_r106['year'].astype(str) + 'Q' + opm_r106['quarter'].astype(str)
opm_season_end = opm_r106[['coid', 'year', 'quarter', 'acc_value']].rename(columns={'acc_value': 'ç‡Ÿæ¥­åˆ©ç›Šç‡'})
##ç‡Ÿæ¥­åˆ©ç›Šç‡
panel_df['ç‡Ÿæ¥­åˆ©ç›Šç‡'] = panel_df.merge(opm_season_end, on=['coid', 'year', 'quarter'], how='left')['ç‡Ÿæ¥­åˆ©ç›Šç‡_y']

money_instance = MONEY(year_df)
money_result_df = money_instance.generate_df('7210')

money_result_df['year'] = pd.to_datetime(money_result_df['mdate']).dt.year
money_result_df['month'] = pd.to_datetime(money_result_df['mdate']).dt.month
money_result_df['quarter'] = ((money_result_df['month'] - 1) // 3) + 1

money_7210 = money_result_df.copy()

# å»ºç«‹å¹´+å­£æ¬„ä½ä»¥ä¾¿æ’åºèˆ‡å¯è¦–åŒ–
money_7210['year_quarter'] = money_7210['year'].astype(str) + 'Q' + money_7210['quarter'].astype(str)
money_season_end = money_7210[['coid', 'year', 'quarter', 'acc_value']].rename(columns={'acc_value': 'ç‡Ÿæ¥­ç¾é‡‘æµ'})
##ç‡Ÿæ¥­ç¾é‡‘æµ
panel_df['ç‡Ÿæ¥­ç¾é‡‘æµ'] = panel_df.merge(money_season_end, on=['coid', 'year', 'quarter'], how='left')['ç‡Ÿæ¥­ç¾é‡‘æµ_y']
panel_df['ç‡Ÿæ¥­ç¾é‡‘æµ'] = panel_df['ç‡Ÿæ¥­ç¾é‡‘æµ']*1000

panel_cleaned = panel_df.dropna(axis=1, how='all')
panel_cleaned_2 = panel_cleaned.dropna().copy()
# panel_cleaned.to_csv("/Users/jeff/Desktop/Business Cycle/cleaned_output.csv", index=False, encoding='utf-8-sig')

features = ['ç‡Ÿæ”¶ YoY', 'å­˜è²¨ YoY', 'æ¯›åˆ©ç‡', 'ç‡Ÿæ¥­åˆ©ç›Šç‡', 'ç‡Ÿæ¥­ç¾é‡‘æµ']

# å°‡ inf è½‰æˆ NaN
panel_cleaned_2.loc[:, features] = panel_cleaned_2.loc[:, features].replace([np.inf, -np.inf], np.nan)

# ç§»é™¤å«æœ‰ NaN çš„ã€Œè©²ç­†è³‡æ–™ã€ï¼ˆå³ï¼šæŸå€‹è‚¡æŸå­£ï¼‰
panel_cleaned_2 = panel_cleaned_2.dropna(subset=features)

for col in ['æ¯›åˆ©ç‡', 'ç‡Ÿæ¥­åˆ©ç›Šç‡']:
    panel_cleaned_2 = panel_cleaned_2[
        (panel_cleaned_2[col] > -100) & (panel_cleaned_2[col] < 100)
    ]
    
panel_cleaned_2['ç‡Ÿæ”¶ YoY'] = panel_cleaned_2['ç‡Ÿæ”¶ YoY'].clip(lower=-100, upper=300)






panel_cleaned_2['date'] = pd.PeriodIndex.from_fields(
    year=panel_cleaned_2['year'],
    quarter=panel_cleaned_2['quarter'],
    freq='Q'
).to_timestamp()

indicators = ['ç‡Ÿæ”¶ YoY', 'å­˜è²¨ YoY', 'æ¯›åˆ©ç‡', 'ç‡Ÿæ¥­åˆ©ç›Šç‡', 'ç‡Ÿæ¥­ç¾é‡‘æµ']

def rolling_percentile(group):
    group = group.sort_values('date').reset_index(drop=True)

    coid = group['coid'].iloc[0]
    result = group[['year', 'quarter', 'date']].iloc[12:].copy()
    result['coid'] = coid

    for indicator in indicators:
        scores = []
        for i in range(12, len(group)):
            window = group.iloc[i-12:i]
            current = group.iloc[i][indicator]

            # è¨ˆç®—åˆ†ä½æ•¸
            percentile = (window[indicator] < current).mean()
            scores.append(percentile)

        # å°æ‡‰åˆ° 1~5 åˆ†æ•¸
        bins = [-0.01, 0.2, 0.4, 0.6, 0.8, 1]
        labels = [1, 2, 3, 4, 5]
        result[indicator + '_percentile'] = scores
        result[indicator + '_score'] = pd.cut(scores, bins=bins, labels=labels).astype(int)

    return result

results = []
for coid, group in panel_cleaned_2.groupby('coid'):
    df = rolling_percentile(group)
    df['coid'] = coid  # æ‰‹å‹•è£œå› coid
    results.append(df)

df_out = pd.concat(results).reset_index(drop=True)

features_2 = ['ç‡Ÿæ”¶ YoY_score', 'å­˜è²¨ YoY_score', 'æ¯›åˆ©ç‡_score', 'ç‡Ÿæ¥­åˆ©ç›Šç‡_score', 'ç‡Ÿæ¥­ç¾é‡‘æµ_score']
X = df_out[features_2]

# PCA
pca = PCA()
X_pca = pca.fit_transform(X)

# å»ºç«‹ä¸»æˆåˆ†åç¨±
pc_names = [f'PC{i+1}' for i in range(pca.components_.shape[0])]

# å»ºç«‹ DataFrame é¡¯ç¤ºæ¯å€‹ä¸»æˆåˆ†çš„ loading
loadings_df = pd.DataFrame(pca.components_, columns=features, index=pc_names)





# # åŠ å…¥ç¶œåˆæ™¯æ°£å¾—åˆ†
# df_out.loc[:, 'ç¶œåˆæ™¯æ°£å¾—åˆ†'] = X_pca[:, 0]

# # å¯é¸ï¼šæª¢è¦– PCA è§£é‡‹çš„è®Šç•°
# explained_variance_ratio = pca.explained_variance_ratio_


# # å…ˆå»ºç«‹ä¸€å€‹æ—¥æœŸæ¬„ä½ï¼Œæ ¼å¼å¯ä»¥æ˜¯ "YYYY-QX"
# df_out.loc[:, 'Date'] = df_out['year'].astype(str) + '-Q' + df_out['quarter'].astype(str)

# # é¸å–é—œéµæ¬„ä½ï¼Œä¸¦åšå¯¬æ ¼å¼è½‰æ›
# df_pivot = df_out.pivot(index='Date', columns='coid', values='ç¶œåˆæ™¯æ°£å¾—åˆ†')

# # é‡è¨­ç´¢å¼•è®“ Date æˆç‚ºæ¬„ä½
# df_pivot.reset_index(inplace=True)

# df_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'] = df_pivot.drop(columns=['Date']).mean(axis=1)




def compute_prosperity_score(df_out, X_pca, pca, n_components=1):
    """
    æ ¹æ“šå‰ n å€‹ä¸»æˆåˆ†è¨ˆç®—ç¶œåˆæ™¯æ°£å¾—åˆ†ï¼Œä¸¦è¼¸å‡ºå¯¬æ ¼å¼è¡¨æ ¼ã€‚
    
    åƒæ•¸ï¼š
        df_out: åŸå§‹è³‡æ–™ï¼ˆåŒ…å« year, quarter, coidï¼‰
        X_pca: PCA è½‰æ›å¾Œçš„è³‡æ–™ï¼ˆé€šå¸¸æ˜¯ pca.transform(X) çš„çµæœï¼‰
        pca: å·²æ“¬åˆçš„ PCA æ¨¡å‹
        n_components: è¦ä½¿ç”¨å¹¾å€‹ä¸»æˆåˆ†è¨ˆç®—æ™¯æ°£åˆ†æ•¸ï¼ˆé è¨­ç‚º 1ï¼‰
    
    å›å‚³ï¼š
        df_pivot: å¯¬æ ¼å¼è³‡æ–™ï¼Œå«æ¯å®¶å…¬å¸èˆ‡ç”¢æ¥­å¹³å‡çš„æ™¯æ°£å¾—åˆ†
    """
    # é™åˆ¶æœ€å¤§ä¸èƒ½è¶…éä¸»æˆåˆ†æ•¸
    n_components = min(n_components, X_pca.shape[1])

    # å–å‡ºå‰ n å€‹ä¸»æˆåˆ†çš„åŠ æ¬Šå¹³å‡ï¼ˆä¾ç…§è§£é‡‹è®Šç•°æ¯”ä¾‹ï¼‰
    weights = pca.explained_variance_ratio_[:n_components]
    weights = weights / weights.sum()  # è®“æ¬Šé‡ç¸½å’Œç‚º 1
    weighted_score = (X_pca[:, :n_components] * weights).sum(axis=1)

    # åŠ å…¥æ™¯æ°£å¾—åˆ†æ¬„ä½
    df_out = df_out.copy()
    df_out['ç¶œåˆæ™¯æ°£å¾—åˆ†'] = weighted_score

    # å»ºç«‹æ™‚é–“æ¬„ä½
    df_out['Date'] = df_out['year'].astype(str) + '-Q' + df_out['quarter'].astype(str)

    # å¯¬æ ¼å¼è½‰æ›
    df_pivot = df_out.pivot(index='Date', columns='coid', values='ç¶œåˆæ™¯æ°£å¾—åˆ†')
    df_pivot.reset_index(inplace=True)

    # åŠ ç¸½ç”¢æ¥­å¹³å‡æ™¯æ°£åˆ†æ•¸
    df_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'] = df_pivot.drop(columns=['Date']).mean(axis=1)

    return df_pivot


df_pivot = compute_prosperity_score(df_out, X_pca, pca, n_components=1)


test = compute_prosperity_score(df_out, X_pca, pca, n_components=1)









# å‡è¨­ df_pivot['Date'] é•·é€™æ¨£: '2012-Q1' æ ¼å¼
quarter_to_month = {"Q1": "03", "Q2": "06", "Q3": "09", "Q4": "12"}

# è½‰æˆæœˆä»½èµ·å§‹æ—¥ï¼ˆQ1 â†’ 03æœˆ1æ—¥ï¼‰
df_pivot["base_date"] = df_pivot["Date"].apply(
    lambda x: pd.to_datetime(f"{x[:4]}-{quarter_to_month[x[-2:]]}-01")
)

# å»¶å¾Œå…©å€‹æœˆ
df_pivot["date_shifted"] = df_pivot["base_date"] + pd.DateOffset(months=2)


quantile_pivot = df_pivot.copy()

# è¨ˆç®—å››åˆ†ä½
q20 = df_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'].quantile(0.2)
q40 = df_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'].quantile(0.4)
q60 = df_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'].quantile(0.6)
q80 = df_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'].quantile(0.8)

# å°æ‡‰ç‡ˆè™Ÿåˆ†é¡é‚è¼¯
def assign_five_lights(score):
    if score >= q80:
        return 'ğŸ”´ éå¸¸ç†±'
    elif score >= q60:
        return 'ğŸŸ  åç†±'
    elif score >= q40:
        return 'ğŸŸ¡ ç©©å®š'
    elif score >= q20:
        return 'ğŸŸ¢ åå†·'
    else:
        return 'ğŸ”µ éå¸¸å†·'

# æ–°å¢ç‡ˆè™Ÿæ¬„ä½
quantile_pivot['ç‡ˆè™Ÿ'] = quantile_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'].apply(assign_five_lights)

save_data = quantile_pivot[['date_shifted','ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸','ç‡ˆè™Ÿ']].copy()

save_data['ç‡ˆè™Ÿåˆ†æ•¸'] = save_data['ç‡ˆè™Ÿ'].map({
    'ğŸ”´ éå¸¸ç†±': 5,
    'ğŸŸ  åç†±': 4,
    'ğŸŸ¡ ç©©å®š': 3,
    'ğŸŸ¢ åå†·': 2,
    'ğŸ”µ éå¸¸å†·': 1
})

daily_rows = []

for _, row in save_data.iterrows():
    start_date = pd.to_datetime(row['date_shifted'])
    end_date = (start_date + pd.offsets.MonthEnd(0))  # æœ¬æœˆæœ€å¾Œä¸€å¤©
    dates = pd.date_range(start=start_date, end=end_date, freq='D')

    expanded = pd.DataFrame({
        'date': dates,
        'ç‡ˆè™Ÿ': row['ç‡ˆè™Ÿ'],
        'ç‡ˆè™Ÿåˆ†æ•¸': row['ç‡ˆè™Ÿåˆ†æ•¸'],
        'date_shifted': row['date_shifted'],
        'ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸': row['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸']
    })

    daily_rows.append(expanded)

# 4. åˆä½µæ‰€æœ‰æ¯æ—¥è³‡æ–™
daily_data = pd.concat(daily_rows, ignore_index=True)



# å‡è¨­ monthly_data æ˜¯ä½ æä¾›çš„ DataFrameï¼ŒåŒ…å« 'date_shifted', 'ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸', 'ç‡ˆè™Ÿ'
daily_data['end_date'] = daily_data['date_shifted'].shift(-1) - pd.Timedelta(days=1)
daily_data.loc[daily_data['end_date'].isna(), 'end_date'] = pd.Timestamp('2025-04-30')  # æˆ– today()

# å»ºç«‹ç‡ˆè™Ÿå°æ‡‰åˆ†æ•¸
light_score_map = {
    'ğŸ”´ éå¸¸ç†±': 5,
    'ğŸŸ  åç†±': 4,
    'ğŸŸ¡ ç©©å®š': 3,
    'ğŸŸ¢ åå†·': 2,
    'ğŸ”µ éå¸¸å†·': 1
}
daily_data['ç‡ˆè™Ÿåˆ†æ•¸'] = daily_data['ç‡ˆè™Ÿ'].map(light_score_map)

# å±•å¹³ç‚ºæ¯æ—¥è³‡æ–™
all_rows = []
for _, row in daily_data.iterrows():
    daily_dates = pd.date_range(start=row['date_shifted'], end=row['end_date'], freq='D')
    df_daily = pd.DataFrame({
        'date': daily_dates,
        'date_shifted': row['date_shifted'],
        'ç‡ˆè™Ÿ': row['ç‡ˆè™Ÿ'],
        'ç‡ˆè™Ÿåˆ†æ•¸': row['ç‡ˆè™Ÿåˆ†æ•¸'],
        'ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸': row['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸']
    })
    all_rows.append(df_daily)

daily_full = pd.concat(all_rows).reset_index(drop=True)

daily_full_save = daily_full[['date','ç‡ˆè™Ÿåˆ†æ•¸']]

daily_full_save.to_csv('/Users/jeff/Desktop/Business Cycle/Textile_signal_lights/remove_extreme_values/electronic_distribution.csv', index=False)















from nutrlink.helper import get_ohlcv
price_df = get_ohlcv(
        nl,
        tickers="M2329",
        start="2012-01-01",
        end="2025-05-31",
        adjusted=True,
    )

price_df = price_df.reset_index()
price_df['datetime'] = pd.to_datetime(price_df['datetime'])  # ç¢ºä¿æ˜¯ datetime æ ¼å¼
price_df = price_df.set_index(['ticker', 'datetime']).sort_index()

# ä¾ ticker åˆ†çµ„å†è½‰æ›æœˆè³‡æ–™
monthly = (
    price_df.groupby(level='ticker')
            .resample('ME', level='datetime')
            .agg({
                'open': 'first',
                'high': 'max',
                'low': 'min',
                'close': 'last',
                'volume': 'sum'
                })
            .reset_index()
)

from plotly.subplots import make_subplots
import plotly.graph_objects as go
import plotly.io as pio

# é¡è‰²å°æ‡‰è¡¨
color_map = {
    'ğŸ”´ éå¸¸ç†±': 'red',
    'ğŸŸ  åç†±': 'orange',
    'ğŸŸ¡ ç©©å®š': 'gold',
    'ğŸŸ¢ åå†·': 'green',
    'ğŸ”µ éå¸¸å†·': 'blue'
}

marker_colors = quantile_pivot['ç‡ˆè™Ÿ'].map(color_map)

# å»ºç«‹åœ–
fig = make_subplots(
    rows=1, cols=1,
    specs=[[{"secondary_y": True}]],
    subplot_titles=("ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸ vs æœˆæ”¶ç›¤åƒ¹",)
)

# åŠ å…¥æ™¯æ°£åˆ†æ•¸ï¼ˆä¸» y è»¸ï¼‰+ ç‡ˆè™Ÿæ¨™è‰²
fig.add_trace(go.Scatter(
    x=quantile_pivot['date_shifted'],
    y=quantile_pivot['ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸'],
    mode='lines+markers',
    name='ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸',
    line=dict(color='black'),
    marker=dict(color=marker_colors, size=10, symbol='circle'),
    hovertemplate='æ—¥æœŸ: %{x|%Y-%m-%d}<br>æ™¯æ°£åˆ†æ•¸: %{y:.3f}<br>ç‡ˆè™Ÿ: %{text}',
    text=quantile_pivot['ç‡ˆè™Ÿ']
), row=1, col=1, secondary_y=False)

# åŠ å…¥æœˆæ”¶ç›¤åƒ¹ï¼ˆå‰¯ y è»¸ï¼‰
fig.add_trace(go.Scatter(
    x=monthly['datetime'],
    y=monthly['close'],
    mode='lines+markers',
    name='æœˆæ”¶ç›¤åƒ¹',
    line=dict(color='green'),
    hovertemplate='æ—¥æœŸ: %{x|%Y-%m-%d}<br>æ”¶ç›¤åƒ¹: %{y:.2f} å…ƒ'
), row=1, col=1, secondary_y=True)

# Layout è¨­å®š
fig.update_layout(
    height=600,
    title_text="ç”¢æ¥­ç¶œåˆæ™¯æ°£åˆ†æ•¸èˆ‡æœˆæ”¶ç›¤åƒ¹ï¼ˆåŒåœ–é›™ Y è»¸ï¼‰",
    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
)

fig.update_xaxes(title_text="æ—¥æœŸ")
fig.update_yaxes(title_text="æ™¯æ°£åˆ†æ•¸", secondary_y=False)
fig.update_yaxes(title_text="æ”¶ç›¤åƒ¹ (å…ƒ)", secondary_y=True)

pio.renderers.default = 'browser'
fig.show()
